---
title: Input
mode: 'wide'
---

```typescript
const res = await lira.message.create()
```

## Options object

<Tip>
  No matter the provider used the method takes the same options object.
  Switching `provider` is as easy as changing the `model` property.
</Tip>

The following options are the object that you can pass to the `create` method.

```typescript
{
  lira?: LiraMetadata
  max_tokens?: number
  messages: Array<Message>
  model: AnthropicModels | OpenAIModels
  temperature?: number
  top_p?: number
  tools?: Array<Tool>
  tool_choice?: ToolChoice
  stop_sequences?: Array<string>
  stream?: boolean
  openai_options?: OpenAIOptions
  anthropic_options?: AnthropicOptions
}
```

<ParamField body="max_tokens" name="max_tokens" type="number" default="2000">
  The maximum number of tokens to generate. Mind that in case the model
  generates more tokens than this value, the response will be truncated.
</ParamField>

<ParamField body="messages" name="messages" type="Array<Message>" required>
  The array of messages to use as context for the model.

  <Expandable title="System">
  ```typescript
  {
    role: 'system',
    content: string
  }
  ```
  </Expandable>

  <Expandable title="User">
  The user message.
  `Text` based message:
  ```typescript
  {
    role: 'user',
    type: 'text'
    content: string
  }
  ```
  `Image` based message:
  ```typescript
  {
    role: 'user',
    type: 'image'
    content: Array<
    | {
        type: 'url'
        url: string
        /**
         * @Anthropic Not supported
         */
        detail?: 'auto' | 'low' | 'high'
      }
    | {
        type: 'base64'
        source: string
        /**
         * @OpenAI Not supported
         */
        media_type: 'image/jpeg' | 'image/png' | 'image/gif' | 'image/webp'
        /**
         * @Anthropic Not supported
         */
        detail?: 'auto' | 'low' | 'high'
      }
  >
  }
  ```
  <b>NOTE:</b> The `Not supported` annotations are for the providers that do not support the feature. Therefore if you use a feature that is not supported by the provider, the provider will ignore it.
  </Expandable>

  <Expandable title="Assistant">
  The model response.
  `Text` based message:
  ```typescript
  {
    role: 'assistant',
    type: 'text'
    content: string
  }
  ```
  `Image` based message:
  ```typescript
  {
    role: 'assistant',
    type: 'image'
    content: Array<
    | {
        type: 'url'
        url: string
        /**
         * @Anthropic Not supported
         */
        detail?: 'auto' | 'low' | 'high'
      }
    | {
        type: 'base64'
        source: string
        /**
         * @OpenAI Not supported
         */
        media_type: 'image/jpeg' | 'image/png' | 'image/gif' | 'image/webp'
        /**
         * @Anthropic Not supported
         */
        detail?: 'auto' | 'low' | 'high'
      }
  >
  }
  ```
  <b>NOTE:</b> The `Not supported` annotations are for the providers that do not support the feature. Therefore if you use a feature that is not supported by the provider, the provider will ignore it.
  </Expandable>

  <Expandable title="Tool Result">
  The result of a tool previously called by the model.
  <br/>
  <i>AKA Tool (or function) output to be provided to the model to generate the next response</i>
  ```typescript
  {
    role: "tool_result"
    tools: Array<{
      type: 'function'
      data: {
        result: string
        name: string
      }
    }>
    is_error?: boolean
  }
  ```
  </Expandable>
</ParamField>

<ParamField body="model" name="model" type="string" required>
  The model to use for generating the text. Available models are:
  <Expandable title="Anthropic models">
    <ul>
      <li>claude-3-5-sonnet-20240620</li>
      <li>claude-3-opus-20240229</li>
      <li>claude-3-sonnet-20240229</li>
      <li>claude-3-haiku-20240307</li>
    </ul>
  </Expandable>
  <Expandable title="OpenAI models">
    <ul>
      <li>gpt-4o</li>
      <li>gpt-4o-2024-05-13</li>
      <li>gpt-4o-2024-08-06</li>
      <li>gpt-4o-latest</li>
      <li>gpt-4o-mini</li>
      <li>gpt-4o-mini-2024-07-18</li>
      <li>gpt-4-turbo</li>
      <li>gpt-4-turbo-2024-04-09</li>
      <li>gpt-4-0125-preview</li>
      <li>gpt-4-1106-preview</li>
      <li>gpt-4</li>
      <li>gpt-4-32k</li>
      <li>gpt-3.5-turbo</li>
      <li>gpt-3.5-turbo-1106</li>
      <li>gpt-3.5-turbo-0125</li>
      <li>gpt-3.5-turbo-instruct</li>
    </ul>
  </Expandable>
</ParamField>

<ParamField body="metadata" name="metadata" type="LiraMetadata">
All this information are useful for tracking the usage of the API.
<Note>Only if you set the `passIdToUnderlyingLLM` to `true`, the `endUser.id` will be passed to the underlying provider. The other info will NEVER be passed to the underlying provider.</Note>
```typescript
{
  endUser?: {
    id: string
    name?: string
    passIdToUnderlyingLLM?: boolean
  }
  sessionId?: string
  tags?: string[]
  store?: {
    disabled?: boolean
    callback?: LiraStore.Callback
  }
}
```
</ParamField>

<ParamField body="temperature" name="temperature" type="number" default="0.5">
  <b>Min: 0, Max: 1.</b>
  <br />
  Controls the randomness of the generated text. Lower values make the model
  more deterministic and repetitive, while higher values make the model more
  creative and unpredictable.
</ParamField>

<ParamField body="top_p" name="top_p" type="number" default="1">
  <b>Min: 0, Max: 1.</b>
  <br />
  Controls the diversity of the generated text. Lower values make the model more
  repetitive, while higher values make the model more creative and
  unpredictable.
  <br />
  ⚠️ This parameter is mutually exclusive with `temperature`.
</ParamField>

<ParamField body="tools" name="tools" type="Array<Tool>">
The array of tools to be eventually used by the model.
```typescript
{
  type: 'function'
  data: {
    name: string
    description?: string
    properties?: Record<string, unknown>
    required?: Array<string>
  }
}
```
</ParamField>

<ParamField body="tool_choice" name="tool_choice" type="ToolChoice">
The choice of the tool to be used by the model.
<br />
<b>Behavior:</b> If the `type` is `auto`, the model will choose the tool automatically.
```typescript
{
  type: 'auto'
}
```
<br />
<b>Behavior:</b> If the `type` is `tool`, the model will use the tool with the given `name`.
```typescript
{
  type: 'tool'
  name: string
}
```
<br />
<b>Behavior:</b> If the `type` is `required`, the model will be forced to use one of the available tools
```typescript
{
  type: 'required'
}
```
<br />
<b>Behavior:</b> If the `type` is `none`, the model will not use any tool.
```typescript
{
  type: 'none'
}
```
</ParamField>

<ParamField body="stop_sequences" name="stop_sequences" type="Array<string>">
  The array of strings that will cause the model to stop generating tokens.
</ParamField>

<ParamField body="stream" name="stream" type="boolean" default="false">
  If `true`, the model will generate the text in a streaming fashion.
</ParamField>

<ParamField body="openai_options" name="openai_options" type="OpenAIOptions">
The following options are specific to the OpenAI models. This means that they will be ignored if you use another provider.
<Info>For more info about those options check [OpenAI docs](https://platform.openai.com/docs/api-reference/chat/create#chat-create-response_format)</Info>
```typescript
{
  presence_penalty?: number
  frequency_penalty?: number
  response_format?: {
    type: "text"
  } | {
    type: "json_object"
  } | {
    type: "json_schema"
    json_schema: {
      description?: string
      name: string
      schema: Record<string, unknown>
      strict?: boolean
    }
  }
  service_tier?: 'auto' | 'default'
  parallel_tool_calls?: boolean
  logprobs?: boolean
  top_logprobs?: number
  seed?: number
  stream_options?: {
    include_usage?: boolean
  }
  logit_bias?: Record<string, number>
}
```
</ParamField>

<ParamField body="anthropic_options" name="anthropic_options" type="AnthropicOptions">
The following options are specific to the Anthropic models. This means that they will be ignored if you use another provider.
<Info>For more info about those options check [Anthropic docs](https://docs.anthropic.com/en/api/messages)</Info>
```typescript
{
  top_k?: number
}
```

</ParamField>
