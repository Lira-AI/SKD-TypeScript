---
title: Message
mode: 'wide'
---

## Configuring the store

The store object is a data structure that holds the input, output, request time, and error of a message. You can enable the store by setting the `store.enabled` option to `true`. Then you can provide a custom callback that takes the store object as a parameter and will be called after the model has generated a response.<br/>

<b>This is the store object schema:</b>
```typescript
store?: {
  enabled: boolean
  callback?: (data: LiraMessageObjStore) => Promise<void> | void
}
```
<Note>The callback is NOT awaited, to avoid blocking the main thread.</Note>

The store settings can be set `globally` in the lira instance or `per-request` in the create message method.

<Warning>`per-request` settings will override the `globally` settings.</Warning>
<CodeGroup>
```typescript globally
const lira = new Lira({
  [...]
  store: {
    enabled: true,
    callback: async (data) => {
      console.log(data)
    }
  }
  [...]
})
```
```typescript per-request
const res = await lira.message.create({
  [...]
  store: {
    enabled: true,
    callback: async (data) => {
      console.log(data)
    }
  }
  [...]
})
```
</CodeGroup>

## Store Object schema

This is the store object schema that will be passed to the callback function.

<br />
`LiraMessageObjStore`:

```typescript
{
  input: LiraMessageInputStore;
  output?: LiraMessageOutputStore;
  reqTime?: LiraMessageReqTimesStore;
  error?: unknown;
}
```

<ParamField  body="input" name="input" type="LiraMessageInputStore" required>
  The same input object that was sent to the model to generate the response.
  [Input object schema](/sdk-reference/message/input).
  <br/>Pluse the optional `provider` field that holds the provider that was used to generate the response.

```typescript
{
  provider?: "Anthropic" | "OpenAI"
  lira?: LiraMetadata
  max_tokens?: number
  messages: Array<Message>
  model: AnthropicModels | OpenAIModels
  temperature?: number
  top_p?: number
  tools?: Array<Tool>
  tool_choice?: ToolChoice
  stop_sequences?: Array<string>
  stream?: boolean
  openai_options?: OpenAIOptions
  anthropic_options?: AnthropicOptions
}
```

</ParamField >

<ParamField body="output" name="output" type="LiraMessageOutputStore">
  The same output object that was generated by the model, described in the
  stream section. [Output object stream
  schema](/sdk-reference/message/output/stream).
  
  ```typescript
  {
    id?: string
    model?: string
    message: AssistantResponse | ToolUseResponse
    stop_reason?: StopReason
    stop_sequence?: string
    usage?: Usage
    logprobs?: Logprobs
    openai_options?: OpenAIOptions
  }
  ```
</ParamField>

<ParamField body="reqTime" name="reqTime" type="LiraMessageReqTimesStore">
  The request time object holds the time range it took to generate the response.
  ```typescript
  { 
    start: number;
    end: number;
  }
  ```
</ParamField>

<ParamField body="error" name="error" type="unknown">
  The error object holds the error that was thrown during the generation of the
  response.
</ParamField>
